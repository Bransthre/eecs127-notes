\chapter{Linear Programs}

\section{Mathematically Expressing Linear Programs}
\begin{ln-define}{Linear Program}{}
    A linear program is an optimization problem with a linear objective function and linear constraints.
    \tcblower
    LPs (linear programs) are genreally phrased as:
    \[
        \min_{A \vec{x} \leq \vec{b}} \vec{c}^T \vec{x}
    \]
    and standardly phrased as:
    \[
        \min_{
            \substack{
                \vec{x} \geq 0 \\
                A \vec{x} = b
            }
        } \vec{c}^T \vec{x}
    \]
\end{ln-define}
Interestingly, any linear program can be written in a standard form.

\subsection{Translating General Forms into Standard Forms}
Here, we provide a part-by-part process on how to translate LPs in General Forms into Standard Forms.

\textbf{Translating Constraints.}
\begin{quote}
    For any constraint $f_i$:
    \[
        \sum_{j = 1}^n A_{i,j} x_j \leq b_j
    \]
    we may introduce a slack variable $\xi_i \geq 0$, such that we rephrase the above constraint as:
    \[
        \sum_{j = 1}^n a_{i,j} x_j + \xi_i = b_i
    \]
    such that the dimensionality of our problem has increased (which increases the computational cost), but we may rephrase inequality constraints as equality constraints.
\end{quote}

\textbf{Dealing with $x_i$ that are not constrained to be positive.}
\begin{quote}
    Any nonpositive number can be written as the difference of two positive numbers. \\
    Using this mathematical fact, we may state that:
    \[
        x_i = x_i^+ - x_i^-, \text{ where } x_i^+, x_i^- \geq 0
    \]
\end{quote}

Let us demonstrate the translation process with the following examples:
\begin{ln-explain}{Example in Translating LP Across Forms}{}
    For the following provided problem:
    \[
        \min_{
            \substack{
                x_1 + x_2 \geq 3 \\
                2x_1 + 2x_2 = 14 \\
                x_1 \geq 0
            }
        } 2 x_1 + 4 x_2
    \]
    translate it into its standard form.
    \tcblower
    Let us first rephrase that,
    \[
        x_2 = x_2^+ - x_2^-, \text{ where } x_2^+, x_2^- \geq 0
    \]
    and introduce a new variable $x_3$ as a slack variable such that:
    \[
        x_1 + x_2 - x_3 = 3
    \]
    Therefore, we translate the linear program into its standard form as:
    \[
        \min_{
            \substack{
                x_1, x_2^+, x_2^-, x_3 \geq 0 \\
                x_1 + x_2^+ - x_2^- - x_3 = 3 \\
                3x_1 + 2x_2^+ - 2x_2^- = 14
            }
        } (2 x_1 + 4 x_2^+ - 4x_2^-)
    \]
\end{ln-explain}

Now, let us look at a slightly more complicated example:
\begin{ln-explain}{Example in Translating LP Across Forms}{}
    For the following presented problem:
    \[
        \min_{
            \substack{
                x_1 + 2x_2 \leq 3 \\
                2x_1 + x_2 \leq 3
            }
        } \begin{bmatrix} -1 \\ -1 \end{bmatrix}^T \vec{x}
    \]
    translate such LP into its standard form.
    \tcblower
    We may introduce slack variables $\xi_1, \xi_2 \geq 0$, such that we rephrase the inequality constraints as
    \[
        \begin{cases}
            x_1 + 2x_2 \leq 3 &\rightarrow x_1 + 2x_2 + \xi_1 = 3 \\
            2x_1 + x_2 \leq 3 &\rightarrow 2x_1 + x_2 + \xi_2 = 3
        \end{cases}
    \]
    Furthermore, as both $x_1$ and $x_2$ are not constrained to be nonnegative, we would add four more variables to rephrase them as the arithmetic results of nonnegative numbers:
    \begin{align*}
        x_1 &= x_1^+ - x_1^-, \text{ where } x_1^+, x_1^- \geq 0 \\
        x_2 &= x_2^+ - x_2^-, \text{ where } x_2^+, x_2^- \geq 0
    \end{align*}
    The resulting standard form of LP would then be:
    \[
        \min_{
            \substack{
                x_1^+, x_1^-, x_2^+, x_2^-, \xi_1, \xi_2 \geq 0 \\
                x_1^+ - x_1^- + 2 (x_2^+ - x_2^-) + \xi_1 = 3 \\
                2 (x_1^+ - x_1^-) + x_2^+ - x_2^- + \xi_2 = 3
            }
        } \begin{bmatrix} -1 \\ -1 \end{bmatrix}^T \vec{x}
    \]
    Furthermore, as we observe the graph of the above linear program, we will discover that the minimum lies on the intersection.
\end{ln-explain}
For linear programs, its optimum lies on what we call an extreme point, where the two constraints of our aforementioned LP in Example 20.1.2 intersect.
\begin{ln-define}{Extreme Point}{}
    A point $p$ of a contex set $\mathcal{S}$ is an extreme point if each line segment that lies completely in $\mathcal{S}$ and contains $p$ has $p$ as an endpoint. \\
    An extreme point is also called a corner point. \\
    Quoted per written \href{http://www.columbia.edu/~cs2035/courses/csor4231.F09/lpdef.pdf}{this source}.
\end{ln-define}

\section{Interior Point}
Let us define the interior points of a linear program's feasible region:
\begin{ln-define}{Interior Point}{}
    We may say $\vec{x}$ is an interior point of some set $\mathcal{X}$ if
    \[
        \exists \epsilon > 0, (\forall \vec{z} \in \mathcal{X}, \pnorm{\vec{x} - \vec{z}}{2} \leq \epsilon)
    \]
    put in a literal sense: if there exists a disk of positive radius centered at $\vec{x}$ that entirely exists in $\mathcal{X}$.
\end{ln-define}
Hereby, we introduce the following theorem:
\begin{ln-theorem}{Optimality of Extreme Point}{}
    \textbf{Theorem.} For a linear program:
    \[
        \min_{\vec{x} \in \mathcal{X}} \vec{c}^T \vec{x}
    \]
    where $\mathcal{X}$ is a closed set such that it contains its boundary, if $\vec{x}^*$ is an optimal solution, then $\vec{x}^*$ exists on the boundary of $\mathcal{X}$.
    \tcblower
    \textbf{Proof.} Suppose that $\vec{x}^*$ is the optimizing argument of the linear program.
    For the sake of contradiction, suppose that $\vec{x}^*$ is an interior point of the feasible region $\mathcal{X}$, such that
    \[
        \exists \epsilon > 0, (\forall \vec{z} \in \mathcal{X}, \pnorm{\vec{x} - \vec{z}}{2} \leq \epsilon)
    \]
    Now, consider $\vec{z} = \vec{x}^* - \alpha \vec{c}$, such that $\pnorm{\vec{x}^* - \vec{z}}{2} = \pnorm{\alpha \vec{c}}{2} < \epsilon$. \\
    Then,
    \begin{align*}
        \vec{c}^T \vec{z}
        &= \vec{c}^T (\vec{x}^* - \alpha \vec{c}) \\
        &= \vec{c}^T \vec{x}^* - \alpha \pnorm[2]{\vec{c}}{2} \\
        &\leq \vec{c}^T \vec{x}^*
    \end{align*}
    We reach the contradiction against the assumption that $\vec{x}^*$, the optimizing argument, is an interior point. \\
    Consequently, the optimal argument $\vec{x}^*$ can never be an interior point, and must lie on the boundary of $\mathcal{X}$.
\end{ln-theorem}
Furthermore, linear programs' optimal arguments are at what we call an extreme point.
\begin{ln-define}{Polyhedron}{}
    A polyhedron is a set:
    \[
        \mathcal{P} = 
        \{
            \vec{x} \in \R^n | A \vec{x} \geq \vec{b}, C \vec{x} = \vec{d}, A \in \R^{m \times n}, \vec{b} \in \R^m
        \}
    \]
    in other words, some set whose points are defined by a linear constraint. \\
    Keep in mind that polyhedrons are not necessarily closed sets, but are always convex.
\end{ln-define}
\begin{ln-define}{Extreme Point}{}
    Let $\mathcal{P}$ be some polyhedron. \\
    Then, $\vec{x}$ is an extreme point if we cannot find two vectors $\vec{y}, \vec{z} \in \mathcal{P}$ (that are distinct form $\vec{x}$ itself) and $\theta \in [0, 1]$ such that $\vec{x} = \theta \vec{y} + (1 - \theta) \vec{z}$. \\
    Written as an implication:
    \[
        \big[\not\exists \vec{y}, \vec{z} \in (\mathcal{P} - \{\vec{x}\}), \theta \in [0, 1]\ \big(\vec{x} = \theta \vec{y} + (1 - \theta) \vec{z} \big)\ \big] \Leftrightarrow \vec{x} \text{ is an extreme point}
    \]
    Therefore, this is to say that an extreme point is any point in the polyhedron that cannot be expressed as the convex combination of any other two vectors within the polyhedron.
\end{ln-define}
Then, our arguments are as follows:
\begin{ln-theorem}{Existence of Solution in Linear Program}{}
    \textbf{Theorem.}
    Consider some linear program:
    \[
        \min_{\vec{x} \in \mathcal{P}} \vec{c}^T \vec{x}
    \]
    Assume $\mathcal{P}$ has at least one extreme point, and an optimal solution exists and is finite.
    Then, there exists an optimal solution that is an extreme point of $\mathcal{P}$.
    \tcblower
    \textbf{Proof.}
    Because we assume $\mathcal{P}$ to have at least one extreme point, it must not contain a line (if it does contain a line, there can't be any extreme points, because extreme points are essentially the intersection of bounds of polyhderon). \\
    Then, suppose that $v^*$ is an optimal solution of the addressed linear program, where the solution exists by assumption of theorem.
    We may phrase all possible points presenting this optimal solution to be:
    \[
        Q = \{\vec{x} | \vec{x} \in \mathcal{P}, \vec{c}^T \vec{x} = v^*\}
    \]
    which is a polyhedron and a subset of $\mathcal{P}$. \\
    Consequently, as $\mathcal{P}$ already does not contain a line, $Q$ cannot contain a line, and must contain an extreme point.

    Suppose $\vec{x}^*$, one of our working solution that belongs to $Q$, is an extreme point of $Q$.
    Then, now, suppose for the sake of contradiction that $\vec{x}^*$ is not an extreme point of $\mathcal{P}$, such that:
    \[
        \exists \vec{y}, \vec{z} \in (\mathcal{P} - \{\vec{x}^*\}), \theta \in (0, 1), \big( \vec{x}^* = \theta \vec{y} + (1 - \theta) \vec{z} \big)
    \]
    From there, 
    \begin{align*}
        \vec{c}^T \vec{x}^* &= v^* \\
        \vec{c}^T [\theta \vec{y} + (1 - \theta) \vec{z}] &= v^* \\
        \vec{c}^T \vec{x}^*
        &= \vec{c}^T [\theta \vec{y} + (1 - \theta) \vec{z}] \\
        &= \theta \vec{c}^T \vec{y} + (1 - \theta) \vec{c}^T \vec{z} = v^*
    \end{align*}
    For the above equality to be satisfied, considering that $\vec{c}^T \vec{y} \geq \vec{c}^T \vec{x}$ and $\vec{c}^T \vec{z} \geq \vec{c}^T \vec{x}$, it must be that
    \[
        \vec{y} = \vec{z} = \vec{x}^*
    \]
    which breaks the premise that $\vec{x}^*$ is an interior point (that $\vec{y} \neq \vec{x}^*$ and so for $\vec{z}$). \\
    Thus, by the above constraint, $\vec{x}^*$ is not an interior, but an extreme point of $\mathcal{P}$.
\end{ln-theorem}
