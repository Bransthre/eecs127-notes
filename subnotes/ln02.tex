\chapter{
    Linear Algebra Bootcamp: Norms, Gram-Schmidt, QR, FTLA
}

\section{Vectors and Norms}
In the previous lecture, we have recognized the following symbol:
\begin{ln-symbol}{Euclidean Norm}{}
    The Euclidiean Norm, otherwise known as a \textbf{2-Norm}, is a mathematical quantity for some vector $\vec{x}$:
    \[
        {\lVert \vec{x} \rVert}_2 = \sqrt{\sum_i x_i^2}
    \]
    which measures the distance between the starting and terminal point of a vector.
\end{ln-symbol}
However, there exist more norms to that. Particularly, \textbf{norms} are functions that satisfy the following properties:
\begin{ln-define}{Norm}{}
    A norm is a function $f: \mathcal{X} \rightarrow \R$ such that:
    \begin{bindenum}
        \item[1.] Non-negativeness: $\forall \vec{x} \in \mathcal{X}, \lVert \vec{x} \rVert \geq 0$, and $\lVert \vec{x} \rVert = 0 \iff \vec{x} = \vec{0}$
        \item[2.] Triangle Inequality: $\forall \vec{x}, \vec{y} \in \mathcal{X}, \lVert \vec{x} + \vec{y} \rVert \leq \lVert \vec{x} \rVert + \lVert \vec{y} \rVert$
        \item[3.] Scalar Multiplication: $\forall \alpha \in \R, \vec{x} \in \mathcal{X}, \lVert \alpha \vec{x} \rVert = \alpha \lVert \vec{x} \rVert$
    \end{bindenum}
\end{ln-define}
For example, a general family of norms that satisfy the above properties would be the \textbf{LP-norms}:
\begin{ln-define}{LP-Norms}{}
    LP-Norms are norm functions defined as:
    \[
        {\lVert \vec{x} \rVert}_p = {\bigg( \sum_{i = 1}^n |x_i|^p \bigg)}^{\frac{1}{p}}
    \]
    for some natural number $p$. \\
    Particularly, the Euclidean Norm, otherwise known as the \textit{2-norm} is LP-norm with $p = 2$. \\
    And, the interesting observation is:
    \begin{align*}
        {\lVert \vec{x} \rVert}_1 &= \sum_{i = 1}^n |x_i| \\
        {\lVert \vec{x} \rVert}_\infty &= \max_{i = 1, \dots, n} |x_i| \\
    \end{align*}
\end{ln-define}

\section{Cauchy-Schwartz Inequality}
This inequality was active in EECS 16A!
\begin{ln-define}{Cauchy-Schwartz Inequality}{}
    The inequality is phrased as:
    \[
        |\vec{x}^T \vec{y}| \leq {\lVert \vec{x} \rVert}_2 {\lVert \vec{y} \rVert}_2
    \]
    And using the property,
    \[|\forall x \in \R, |\cos(x)| \leq 1\]
    this inequality originates from the following algebraic work:
    \begin{align*}
        |\langle \vec{x}, \vec{y} \rangle| &= |\vec{x}^T \vec{y}| = |\vec{y}^T \vec{x}| \\
        &= |{\lVert \vec{x} \rVert}_2 {\lVert \vec{y} \rVert}_2 \cos(\theta_{\vec{x}, \vec{y}})| \\
        &\leq |{\lVert \vec{x} \rVert}_2 {\lVert \vec{y} \rVert}_2|
    \end{align*}
\end{ln-define}

The last two lines of the above derivation is justified by the mechanics along which we find the projection of $\vec{x}$ onto $\vec{y}$:
\[
    {proj}_{\vec{x}}^{\vec{y}} = \vec{y} \frac{\vec{x}^T\vec{y}}{{\lVert \vec{y} \rVert}_2^2}
\]
Where, since the projection is a multiple of $\vec{y}$ such that ${proj}_{\vec{x}}^{\vec{y}} = t\vec{y}$, we also recognize that,
\[
    \cos(\theta_{\vec{x}, \vec{y}}) = \frac{{\lVert t\vec{y} \rVert}_2}{{\lVert \vec{x} \rVert}_2}
\]
And upon matching the two equations, I acquire:
\begin{align*}
    t = \cos(\theta_{\vec{x}, \vec{y}}) \frac{{\lVert t\vec{x} \rVert}_2}{{\lVert \vec{y} \rVert}_2} &= \frac{\vec{x}^T\vec{y}}{{\lVert \vec{y} \rVert}_2^2} \\
    |{\lVert \vec{x} \rVert}_2 {\lVert \vec{y} \rVert}_2| &= \langle \vec{x}, \vec{y} \rangle
\end{align*}

\subsection{Holder's Inequality and Norm Ball}
In fact, we find that the Cauchy-Schwartz is a general case of this inequality:
\begin{ln-define}{Holder's Inequality}{}
    Provided the quantities
    \[\vec{x}, \vec{y} \in \R^n, \text{and some } p, q \geq 1 \text{ s.t. } \frac{1}{p} + \frac{1}{q} = 1\]
    Then, 
    \[|\vec{x}^T \vec{y}| \leq {\lVert \vec{x} \rVert}_p{\lVert \vec{y} \rVert}_p\]
\end{ln-define}
From this concept, let us consider the concept of \textit{``norm ball''}: the geographical object containing all vectors such that their lp-norm is $1$.

\begin{bindenum}
    \item For a $2-norm$, for example, the norm ball looks like a unit circle (containing all 2D vectors with length $1$, hence a circle of radius $1$).
    \item For a $1-norm$, similar logic guides us to a diagonally placed circle (rotated $45^\circ$) centered at the origin with side lengths $2$.
    \item For the $\infty-norm$, has a norm ball of a square centered at origin with side length $2$. This embeds the unit ball from $2-norm$, which embeds the unit ball from $1-norm$.
\end{bindenum}
In this sense, the area of norm ball is larger for any increase in $p$ such that it embeds the prior norm balls.

\begin{ln-explain}{Optimization Problem Regarding Norm Ball}{}
    \textbf{Problem Formulation:} Solve for \[\max_{{\Vert \vec{x} \rVert}_2 \leq 1} \vec{x}^T \vec{y}\]
    \tcblower
    \textbf{p = 2}: The solution would be, by the Cauchy Schwartz's implication,
    \[\vec{x}^* = \frac{\vec{y}}{\lVert \vec{y} \rVert}_2\]
    \textbf{p = 1}: The expression of dot product is equivalently
    \[x_1 y_1 + \cdots + x_n y_n\]
    Where the constraint is
    \[|x_1| + \cdots + |x_n| \leq 1\]
    For each value the components of $\vec{x}$, which is finite and upper bounded by $1$, we should allocate maximum contribution to the maximum element of $\vec{y}$ to maximize this dot product (a weighted sum of $\vec{y}$'s component, essentially). \\
    Therefore, let $i$ be the index at which $\vec{y}$ has the component of largest absolute value,
    \begin{quote}
        There is an achievable solution for $\vec{x}^*$, being the unit vector $\vec{e}_i$ multiplied by $sgn(y_i)$, so to counter for cases where $\vec{y}$ is negative.
    \end{quote}
    \par
    In turn, we see that
    \[\vec{x}^T \vec{y} = \max_i |y_i| = {\lVert \vec{y} \rVert}_\infty\]
    Meanwhile, let us use the Holder's Inequality to achieve a more rigorous proof. Holder's Inequality states that,
    \[
        |\vec{x}^T \vec{y}| \leq {\lVert \vec{x} \rVert}_1 {\lVert \vec{y} \rVert}_\infty = \max_i |y_i|
    \]
    Where,
    \begin{quote}
        \textbf{The formulation in above section shows achievability, and Holder's Inequality expresses an upper bound to prove the approach correct.}
    \end{quote}
    \textbf{\textit{Alternative proof of p = 1 via Triangle Inequality}}: Via the triangle inequality, we acquire:
    \begin{align*}
        |\vec{x}^T \vec{y}| &= |\sum_i x_i y_i| \\
        &\underset{Triangle\ Inequality}{\leq} \sum_i |x_i y_i| \\
        &= \sum_i |x_i||y_i| \\
        &\leq \sum_i |x_i| \max_i |y_i| = \max_i |y_i| = {\lVert \vec{x} \rVert}_\infty
    \end{align*}
    We see that the upperbound of $|\vec{x}^T \vec{y}|$ \textbf{has an upperbound} that is \textbf{achievable}, assembling all necessary aspects of a complete proof. \\
    \textbf{p = $\infty$}: We can find upper bound via Holder's Inequality,
    \[
        |\vec{x}^T \vec{y}| \leq {\lVert \vec{x} \rVert}_1 {\lVert \vec{y} \rVert}_\infty = \sum_i |y_i|
    \]
    The infinity norm of $\vec{x}$ shows the constraint that:
    \[
        \max_i |x_i| = 1
    \]
    and we may simply compute:
    \[
        x_i = sgn(y_i)
    \]
    to find and certify the achievability of this upper bound.
\end{ln-explain}

\section{Gram-Schmidt Orthonormalization and QR Decomposition}
Gram-Schmidt Orthonormalization is an algorithmic technique to find an orthonormal basis for a set of vectors. \\
The procedure of such algorithm is portrayed as defined in the following cell:
\begin{ln-define}{The Procedure of Gram-Schmidt Orthonormalization}{}
    Let us have a set of vectors $\{\vec{a_1}, \dots, \vec{a_n}\}$.
    \begin{bindenum}
        \item[1] $\vec{q_1} = \frac{\vec{a_1}}{{\lVert \vec{a_1} \rVert}_2}$
        \item[2] for $i$ in $\{2, \dots, n\}$:
        \item[3] \hspace{0.6cm} $\vec{z_i} = {proj}_{\{\vec{q_1}, \dots, \vec{q_{i - 1}}\}} \vec{a_i}$
        \item[4] \hspace{0.6cm} $\vec{s_i} = \vec{a_i} - \vec{z_i}$
        \item[5] \hspace{0.6cm} $\vec{q_i} = \frac{\vec{s_i}}{{\lVert \vec{s_i} \rVert}_2}$
        \item[6] return $\{\vec{q_1}, \dots, \vec{q_n}\}$
    \end{bindenum}
    And note that,
    \[
        \vec{z_i} = \sum_{j = 1}^{i - 1} \vec{q_j} \langle \vec{a_i}, \vec{q_j} \rangle
    \]
\end{ln-define}
