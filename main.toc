\contentsline {chapter}{\numberline {1}Introduction and Least Squares}{5}{chapter.1}%
\contentsline {section}{\numberline {1.1}An Introductory Prompt}{5}{section.1.1}%
\contentsline {section}{\numberline {1.2}Administratives, Summary}{5}{section.1.2}%
\contentsline {section}{\numberline {1.3}Introduction to The Subject Topic: Optimization}{5}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}An Example of Problem Formulation}{6}{subsection.1.3.1}%
\contentsline {section}{\numberline {1.4}Least Squares Regression}{7}{section.1.4}%
\contentsline {chapter}{\numberline {2} Linear Algebra Bootcamp: Norms, Gram-Schmidt, QR, FTLA }{9}{chapter.2}%
\contentsline {section}{\numberline {2.1}Vectors and Norms}{9}{section.2.1}%
\contentsline {section}{\numberline {2.2}Cauchy-Schwartz Inequality}{10}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Holder's Inequality and Norm Ball}{10}{subsection.2.2.1}%
\contentsline {section}{\numberline {2.3}Gram-Schmidt Orthonormalization and QR Decomposition}{12}{section.2.3}%
\contentsline {chapter}{\numberline {3}Linear Algebra: Symmetric Matrices}{13}{chapter.3}%
\contentsline {section}{\numberline {3.1}Fundamental Theorem of Linear Algebra}{13}{section.3.1}%
\contentsline {section}{\numberline {3.2}Minimum Norm Problem}{14}{section.3.2}%
\contentsline {section}{\numberline {3.3}Principal Component Analysis}{15}{section.3.3}%
\contentsline {chapter}{\numberline {4}Principal Component Analysis}{17}{chapter.4}%
\contentsline {section}{\numberline {4.1}Symmetric Matrix}{17}{section.4.1}%
\contentsline {section}{\numberline {4.2}PCA}{18}{section.4.2}%
\contentsline {chapter}{\numberline {5}SVD and Low-Rank Approximation}{21}{chapter.5}%
\contentsline {section}{\numberline {5.1}Singular Value Decomposition (SVD)}{21}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Formation of SVD}{22}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Geometry of SVD}{23}{subsection.5.1.2}%
\contentsline {section}{\numberline {5.2}Low Rank Approximation}{23}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Matrix Norms}{23}{subsection.5.2.1}%
\contentsline {chapter}{\numberline {6}Low-Rank Approximation}{25}{chapter.6}%
\contentsline {section}{\numberline {6.1}Discussion of L-RA}{25}{section.6.1}%
\contentsline {chapter}{\numberline {7}Vector Calculus}{29}{chapter.7}%
\contentsline {section}{\numberline {7.1}Function Expansion: Taylor Series}{29}{section.7.1}%
\contentsline {section}{\numberline {7.2}Function Expansion: Derivative of Vector Functions}{30}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Matrix in Vector Calculus}{32}{subsection.7.2.1}%
\contentsline {chapter}{\numberline {8}The Extension of Vector Calculus}{33}{chapter.8}%
\contentsline {section}{\numberline {8.1}The Main Theorem}{33}{section.8.1}%
\contentsline {section}{\numberline {8.2}Perturbation Analysis, Effect of Noise}{34}{section.8.2}%
\contentsline {chapter}{\numberline {9}Ridge Regression}{36}{chapter.9}%
\contentsline {section}{\numberline {9.1}Perturbation Analysis Guides into Ridge Regression}{36}{section.9.1}%
\contentsline {section}{\numberline {9.2}Ridge Regression}{36}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Development of Ridge Regression}{37}{subsection.9.2.1}%
\contentsline {section}{\numberline {9.3}Probabilistic Information from Ridge Regression}{38}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}Maximum Likelihood Estimation and Maximum A-Posteriori}{38}{subsection.9.3.1}%
\contentsline {chapter}{\numberline {10}Convexity}{41}{chapter.10}%
\contentsline {section}{\numberline {10.1}Convex Set}{41}{section.10.1}%
\contentsline {subsection}{\numberline {10.1.1}Proof of Convexity}{42}{subsection.10.1.1}%
\contentsline {subsection}{\numberline {10.1.2}Hyperplanes}{43}{subsection.10.1.2}%
\contentsline {section}{\numberline {10.2}Convex Functions}{44}{section.10.2}%
