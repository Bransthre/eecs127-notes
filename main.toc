\contentsline {chapter}{\numberline {1}Introduction and Least Squares}{4}{chapter.1}%
\contentsline {section}{\numberline {1.1}An Introductory Prompt}{4}{section.1.1}%
\contentsline {section}{\numberline {1.2}Administratives, Summary}{4}{section.1.2}%
\contentsline {section}{\numberline {1.3}Introduction to The Subject Topic: Optimization}{4}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}An Example of Problem Formulation}{5}{subsection.1.3.1}%
\contentsline {section}{\numberline {1.4}Least Squares Regression}{6}{section.1.4}%
\contentsline {chapter}{\numberline {2} Linear Algebra Bootcamp: Norms, Gram-Schmidt, QR, FTLA }{8}{chapter.2}%
\contentsline {section}{\numberline {2.1}Vectors and Norms}{8}{section.2.1}%
\contentsline {section}{\numberline {2.2}Cauchy-Schwartz Inequality}{9}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Holder's Inequality and Norm Ball}{9}{subsection.2.2.1}%
\contentsline {section}{\numberline {2.3}Gram-Schmidt Orthonormalization and QR Decomposition}{11}{section.2.3}%
\contentsline {chapter}{\numberline {3}Linear Algebra: Symmetric Matrices}{12}{chapter.3}%
\contentsline {section}{\numberline {3.1}Fundamental Theorem of Linear Algebra}{12}{section.3.1}%
\contentsline {section}{\numberline {3.2}Minimum Norm Problem}{13}{section.3.2}%
\contentsline {section}{\numberline {3.3}Principal Component Analysis}{14}{section.3.3}%
\contentsline {chapter}{\numberline {4}Principal Component Analysis}{16}{chapter.4}%
\contentsline {section}{\numberline {4.1}Symmetric Matrix}{16}{section.4.1}%
\contentsline {section}{\numberline {4.2}PCA}{17}{section.4.2}%
\contentsline {chapter}{\numberline {5}SVD and Low-Rank Approximation}{20}{chapter.5}%
\contentsline {section}{\numberline {5.1}Singular Value Decomposition (SVD)}{20}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Formation of SVD}{21}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Geometry of SVD}{22}{subsection.5.1.2}%
\contentsline {section}{\numberline {5.2}Low Rank Approximation}{22}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Matrix Norms}{22}{subsection.5.2.1}%
\contentsline {chapter}{\numberline {6}Low-Rank Approximation}{24}{chapter.6}%
\contentsline {section}{\numberline {6.1}Discussion of L-RA}{24}{section.6.1}%
\contentsline {chapter}{\numberline {7}Vector Calculus}{28}{chapter.7}%
\contentsline {section}{\numberline {7.1}Function Expansion: Taylor Series}{28}{section.7.1}%
\contentsline {section}{\numberline {7.2}Function Expansion: Derivative of Vector Functions}{29}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Matrix in Vector Calculus}{31}{subsection.7.2.1}%
\contentsline {chapter}{\numberline {8}The Extension of Vector Calculus}{32}{chapter.8}%
\contentsline {section}{\numberline {8.1}The Main Theorem}{32}{section.8.1}%
\contentsline {section}{\numberline {8.2}Perturbation Analysis, Effect of Noise}{33}{section.8.2}%
\contentsline {chapter}{\numberline {9}Ridge Regression}{35}{chapter.9}%
\contentsline {section}{\numberline {9.1}Perturbation Analysis Guides into Ridge Regression}{35}{section.9.1}%
\contentsline {section}{\numberline {9.2}Ridge Regression}{35}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Development of Ridge Regression}{36}{subsection.9.2.1}%
\contentsline {section}{\numberline {9.3}Probabilistic Information from Ridge Regression}{37}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}Maximum Likelihood Estimation and Maximum A-Posteriori}{37}{subsection.9.3.1}%
